import sqlite3import jsonimport reimport mathimport sysfrom collections import defaultdictfrom live_log import emittry:    import spacyexcept ImportError:    print("SpaCy non è installato. Installa spaCy con 'pip install spacy' e il modello italiano con 'python -m spacy download it_core_news_sm'.")    sys.exit(1)DB_PATH = "MachineLearningAlgorithm/knowledge.db"SANITIZE_REGEX = re.compile(r"[^A-Za-zÀ-ÖØ-öø-ÿ0-9]+", re.UNICODE)THRESHOLD_RELATIVE = 0.4  # restituisce tutti i Case con score >= 40% del miglioreMAX_TOP = 5               # numero massimo di Case da mostrare################################################################################ Utility                                                                     ################################################################################def sanitize(text: str) -> str:    """Sostituisce i caratteri non alfanumerici con spazi e rimuove spazi extra."""    return SANITIZE_REGEX.sub(" ", text).strip()################################################################################ Database helpers                                                            ################################################################################def load_patterns(conn: sqlite3.Connection):    cur = conn.cursor()    cur.execute("SELECT id, syntax FROM Pattern")    return [(row[0], json.loads(row[1])) for row in cur.fetchall()]def pattern_scores_for_case(conn: sqlite3.Connection, pattern_ids):    score_per_case = defaultdict(int)    if not pattern_ids:        return score_per_case    cur = conn.cursor()    placeholder = ",".join(["?"] * len(pattern_ids))    cur.execute(        f"SELECT case_id, pattern_id, score FROM Pattern_Scorage WHERE pattern_id IN ({placeholder})",        pattern_ids,    )    for case_id, pattern_id, score in cur.fetchall():        score_per_case[case_id] += score    return score_per_casedef pattern_score_for_single(conn: sqlite3.Connection, case_id: int, pattern_id: int) -> int:    cur = conn.cursor()    cur.execute(        "SELECT score FROM Pattern_Scorage WHERE case_id = ? AND pattern_id = ?",        (case_id, pattern_id),    )    row = cur.fetchone()    return row[0] if row else 0def words_info(conn: sqlite3.Connection, words):    if not words:        return {}, {}, {}    lower_words = [w.lower() for w in words]    placeholders = ",".join(["?"] * len(lower_words))    cur = conn.cursor()    cur.execute(f"SELECT id, word FROM Word WHERE word IN ({placeholders})", lower_words)    rows = cur.fetchall()    word_to_id = {row[1]: row[0] for row in rows}    if not word_to_id:        return {}, {}, {}    tf_per_word_case = defaultdict(dict)    placeholder_ids = ",".join(["?"] * len(word_to_id))    cur.execute(        f"SELECT word_id, case_id, score FROM Word_Scorage WHERE word_id IN ({placeholder_ids})",        list(word_to_id.values()),    )    for wid, case_id, score in cur.fetchall():        tf_per_word_case[wid][case_id] = score    cur.execute('SELECT COUNT(*) FROM "Case"')    n_cases = cur.fetchone()[0] or 1    cur.execute(        f"SELECT word_id, COUNT(*) FROM Word_Scorage WHERE word_id IN ({placeholder_ids}) GROUP BY word_id",        list(word_to_id.values()),    )    df_rows = {row[0]: row[1] for row in cur.fetchall()}    idf = {wid: math.log(n_cases / (1 + df_rows.get(wid, 0))) for wid in word_to_id.values()}    return word_to_id, tf_per_word_case, idf################################################################################ Scoring functions                                                           ################################################################################def score_cases(pattern_case_scores, word_scores_case):    combined = defaultdict(float)    if pattern_case_scores:        max_p = max(pattern_case_scores.values()) or 1        for cid, s in pattern_case_scores.items():            combined[cid] += math.sqrt(max(0, s)) / math.sqrt(max(0.01, max_p))    if word_scores_case:        max_w = max(word_scores_case.values()) or 1        for cid, s in word_scores_case.items():            combined[cid] += math.sqrt(max(0, s)) / math.sqrt(max(0.01, max_w))    return combined################################################################################ Pattern matching                                                            ################################################################################def find_pattern_matches(pos_sequence, patterns):    matches = []    seq_len = len(pos_sequence)    for pid, pat in patterns:        pat_len = len(pat)        if pat_len == 0 or pat_len > seq_len:            continue        for i in range(seq_len - pat_len + 1):            if pos_sequence[i : i + pat_len] == pat:                matches.append({"pattern_id": pid, "start": i, "end": i + pat_len})    return matches################################################################################ Case lookup per pattern                                                     ################################################################################def cases_for_patterns(    conn: sqlite3.Connection, pattern_ids: list[int]) -> tuple[dict[int, list[int]], dict[int, str]]:    """    Ritorna:      • pid_to_cases  = {pattern_id: [case_id, ...]}      • id_to_name    = {case_id   : "CaseName"}    """    if not pattern_ids:        return {}, {}    placeholders = ",".join("?" * len(pattern_ids))    cur = conn.cursor()    cur.execute(        f"""        SELECT ps.pattern_id, c.id, c.name        FROM Pattern_Scorage ps        JOIN "Case" c ON c.id = ps.case_id        WHERE ps.pattern_id IN ({placeholders})        """,        pattern_ids,    )    pid_to_cases = defaultdict(list)    id_to_name = {}    for pid, cid, cname in cur.fetchall():        pid_to_cases[pid].append(cid)        id_to_name[cid] = cname    return pid_to_cases, id_to_name################################################################################ Interactive search loop                                                    ################################################################################def interactive_search(user_input):    with sqlite3.connect(DB_PATH) as conn:        conn.row_factory = sqlite3.Row        try:            nlp = spacy.load("it_core_news_sm")        except OSError:            emit("Modello 'it_core_news_sm' non trovato. Installa con: python -m spacy download it_core_news_sm", "warning")            return        patterns = load_patterns(conn)        pattern_len = {pid: len(plist) for pid, plist in patterns}        sanitized = sanitize(user_input)        if not sanitized:            emit("Input vuoto. Riprova.", "warning")            return        doc = nlp(sanitized)        pos_seq = [t.pos_ for t in doc if t.text.strip()]        matches = find_pattern_matches(pos_seq, patterns)        if not matches:            emit("Nessun pattern trovato nel testo.", "warning")            return        pattern_ids = [m["pattern_id"] for m in matches]        pattern_cases, id_to_name = cases_for_patterns(conn, pattern_ids)        # pattern_cases: {pattern_id: [case1, case2, ...]}        exclusive_for = {            pid: cases[0] for pid, cases in pattern_cases.items() if len(cases) == 1        }        emit("Match trovati:", "thinking")        for m in matches:            seg = doc[m["start"]:m["end"]].text            case_ids = pattern_cases.get(m["pattern_id"], [])            cases_txt = ", ".join(id_to_name[cid] for cid in case_ids) or "?"            emit(f" - Pattern ID {m['pattern_id']} (case: {cases_txt}) -> segment: '{seg}'", "thinking")        pattern_case_scores = pattern_scores_for_case(conn, pattern_ids)        words_in_matches = [doc[i].text.lower() for m in matches for i in range(m["start"], m["end"])]        _, tf_per_word_case, idf = words_info(conn, words_in_matches)        word_scores_case = defaultdict(float)        for wid, cases_tf in tf_per_word_case.items():            for cid, tf in cases_tf.items():                word_scores_case[cid] += tf * idf.get(wid, 0.0)        combined_scores = score_cases(pattern_case_scores, word_scores_case)        if not combined_scores:            emit("Impossibile calcolare punteggi.", "warning")            return        max_score = max(combined_scores.values())        candidates_raw = [cid for cid, s in combined_scores.items()                          if s >= max_score * THRESHOLD_RELATIVE]        # === nuovo filtro “almeno un pattern esclusivo” ==========================        def has_exclusive(cid: int) -> bool:            return any(exclusive_for.get(pid) == cid for pid in pattern_ids)        candidate_ids = [cid for cid in candidates_raw if has_exclusive(cid)]        # fallback di sicurezza: se filtriamo TUTTO, torniamo alla lista grezza        if not candidate_ids:            candidate_ids = candidates_raw        candidate_ids_sorted = sorted(candidate_ids, key=lambda c: combined_scores[c], reverse=True)[:MAX_TOP]        if not candidate_ids_sorted:            emit("Nessun case supera la soglia relativa.", "warning")            return        pattern_to_segment = {m["pattern_id"]: doc[m["start"]:m["end"]].text for m in matches}        cur = conn.cursor()        placeholders = ",".join(["?"] * len(candidate_ids_sorted))        cur.execute(f'SELECT id, name FROM "Case" WHERE id IN ({placeholders})', candidate_ids_sorted)        id_to_name = {row[0]: row[1] for row in cur.fetchall()}        max_p = max(pattern_case_scores.values()) or 1        max_w = max(word_scores_case.values()) or 1        emit("\n==== RISULTATI (ordinati per score) ====")        for cid in candidate_ids_sorted:            best_pattern_id = None            best_relevance = -1.0            for pid in pattern_ids:                score_single = pattern_score_for_single(conn, cid, pid)                if score_single == 0:                    continue                relevance = score_single * (1 + pattern_len.get(pid, 1))                if relevance > best_relevance:                    best_relevance = relevance                    best_pattern_id = pid            segment = pattern_to_segment.get(best_pattern_id)            if segment is None:                continue            emit(                f"* {id_to_name.get(cid, 'ID '+str(cid))}: score={combined_scores[cid]:.3f} | "                f"pattern={pattern_case_scores.get(cid,0)/max_p:.3f} | tf-idf={word_scores_case.get(cid,0)/max_w:.3f} | "                f"pattern segment='{segment}'"            )        #print()  # riga vuota separatrice################################################################################ Entrypoint                                                                  ################################################################################if __name__ == "__main__":    print("Premi Ctrl+C per terminare.\n")    try:        while True:            prompt = str(input("Inserisci la tua richiesta: "))            interactive_search(prompt)    except KeyboardInterrupt:        print("\nInterrotto dall'utente. Arrivederci.")